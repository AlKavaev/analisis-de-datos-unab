\documentclass[11pt,oneside,spanish]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{array}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{tikz}
\usepackage[linkcolor=blue,colorlinks=true,urlcolor=blue]{hyperref}

\usepackage{import}
\graphicspath{{figuras/}}

\usepackage{multicol}

\usepackage{enumerate}

\usepackage{booktabs}

\theoremstyle{definition}
\newtheorem{defi}{Definici\'o혰n}
\newtheorem{car}{Caracterizaci\'o혰n}
\headheight 36pt
\usepackage{geometry}
\geometry{verbose,letterpaper,tmargin=30mm,bmargin=30mm,lmargin=25mm,rmargin=25mm}
\parindent 0em
\parskip 0ex

\newtheorem{ejercicio}{Ejercicio}
\newtheorem{teorema}{Teorema}
\newtheorem{lema}{Lema}
\newtheorem{corolario}{Corolario}
\theoremstyle{definition}\newtheorem{definicion}{Definici혰n}
\theoremstyle{definition}\newtheorem{ejemplo}{Ejemplo}
\theoremstyle{remark}\newtheorem{nota}{\textsc{Nota}}
\theoremstyle{definition}\newtheorem{proposicion}{Proposici혰n}
\theoremstyle{definition}\newtheorem{problema}{Problema}
\newenvironment{demostracion}{\textsc{Demostraci\'{o}n.}}{\halmos}

\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\eq}[1]{\begin{equation} #1 \end{equation}}
\newcommand{\dpr}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\emqc}[1]{#1 \in \N}
\newcommand{\ssuc}{\{x_{n_k}\}_{k\in\N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\sen}{\text{sen}}
\newcommand{\senh}{\text{senh}}
\newcommand{\adh}[1]{\text{adh}({#1})}
\newcommand{\der}[1]{\text{der}({#1})}
\newcommand{\inte}[1]{\text{int}({#1})}
\newcommand{\fr}[1]{\text{fr}({#1})}
\newcommand{\co}[1]{\text{co}({#1})}
\newenvironment{respuesta}{\smallskip \textbf{\textsf{Respuesta}} \sffamily \newline}{\hfill}
\newcommand{\re}[1]{\begin{respuesta} #1 \end{respuesta}}  
\newenvironment{solucion}{\smallskip \textbf{\textsf{Soluci\'on}} \sffamily \newline}{\hfill}
\newcommand{\so}[1]{\begin{solucion} #1 \end{solucion}}  

\makeatletter
\def\ScaleIfNeeded{
\ifdim\Gin@nat@width>\linewidth
\linewidth
\else
\Gin@nat@width
\fi
}
\makeatother

\usepackage[mathlf,textlf,minionint,openg]{MinionPro}
\usepackage[bb=lucida,bbscaled=.95]{mathalfa}
\usepackage[protrusion=true,expansion=true]{microtype}
\renewcommand{\vec}[1]{\boldsymbol{#1}}

\usepackage{listings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{center}
\textbf{Pauta del Primer Control de Laboratorio} 
\end{center}

\bigskip

\begin{enumerate}[(1)]
\item Considere el siguiente vector de datos y el vector de ponderadores
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
 x <- c(0.18, -1.54, 0.42, 0.95)
 w <- c(2, 1, 3, 1)
\end{lstlisting}
{\textquestiondown}Cu\'al es el valor de $\mu$ que minimiza la ecuaci\'on de m\'inimos cuadrados $\sum_{i=1}^n w_i(x_i-\mu)^2$?

\textbf{Desarrollo.}
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> x <- c(0.18, -1.54, 0.42, 0.95)
> w <- c(2, 1, 3, 1)
> weighted.mean(x, w)
[1] 0.1471429\end{lstlisting}
	
\item Considere los siguientes datos
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
 x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44)
 y <- c(1.39, 0.72, 1.55, 0.48, -1.59, 1.23, -0.65, 1.49, 0.05)
\end{lstlisting}
Estime una regresi\'on que pase por el origen considerando $x$ como input e $y$ como output. (Hint: no centre los datos ya que se pide una regresi\'on 	que pase por el origen y no por las medias de los datos.)
{\textquestiondown}Cu\'al es el valor de la pendiente?

\textbf{Desarrollo.}
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44)
> y <- c(1.39, 0.72, 1.55, 0.48, -1.59, 1.23, -0.65, 1.49, 0.05)
> lm( y ~ x - 1 )

 Call:
 lm(formula = y ~ x - 1)

 Coefficients:
     x   
 1.086 
\end{lstlisting}
	
\item Cargue la  base da datos \texttt{mtcars} y estime una regresi\'on que explique la variable \texttt{mpg} en funci\'on de la variable \texttt{wt}. {\textquestiondown}Cu\'al es el coeficiente de la pendiente?	

\textbf{Desarrollo.}
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> data(mtcars)
> lm(mpg ~ wt, mtcars)

 Call:
 lm(formula = mpg ~ wt, data = mtcars)

 Coefficients:
 (Intercept)           wt  
      37.285       -5.344  
\end{lstlisting}

\item Considere una regresi\'on hipot\'etica en la cual $Y$ es el output y $X$ es el input. La desviaci\'on t\'ipica del input es la mitad de la del output. La correlaci\'on entre ambas variables es $0,5$. {\textquestiondown}Cu\'al es el valor de la pendiente de un modelo en el que se invierte el input y el output?

\textbf{Desarrollo.}
De acuerdo a lo visto en clase 
$$\beta = \text{cor}(X,Y) \cdot \frac{\text{sd}(Y)}{\text{sd}(X)} =  1$$
Si se invierte el output y el input el coeficiente de la pendiente es
$$\gamma = \text{cor}(X,Y) \cdot \frac{\text{sd}(X)}{\text{sd}(Y)} = 0.25$$

\item Considere el vector 
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
 x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
\end{lstlisting}
Si se normalizan los datos {\textquestiondown}Cu\'al es el valor de la primera observaci\'on?	

\textbf{Desarrollo.}
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
> mean <- mean(x)
> sd <- sd(x)
> (x-mean)/sd
[1] -0.9718658  1.5310215 -0.3993969  0.4393366 -0.5990954
\end{lstlisting}

\item Sea $\beta_1$ la pendiente de un modelo en el que $Y$ es el output y $X$ es el input. Sea $\gamma_1$ la pendiente de un modelo en el que $X$ es el output e $Y$ es el input. {\textquestiondown}Cu\'al es el valor de $\beta_1 / \gamma_1$?		

\textbf{Desarrollo.}
$$\displaystyle \frac{\beta}{\gamma} = \displaystyle\frac{\text{cor}(X,Y)\cdot \displaystyle \frac{sd(Y)}{sd(X)}}{\text{cor}(X,Y)\cdot \displaystyle \frac{\text{sd}(X)}{\text{sd}(Y)}} = \displaystyle \frac{\text{sd}^2(Y)}{\text{sd}^2(X)} = \displaystyle \frac{\text{var}(Y)}{\text{var}(X)}$$

\item Considere un modelo  lineal con datos hipot\'eticos en el que el input y el output tienen media 0. {\textquestiondown}Qu\'e se puede afirmar respecto del intercepto si se estima una regresi\'on?		

\textbf{Desarrollo.}
En el modelo sin constante la regresi\'on pasa por $(0,0)$. En el modelo con constante la regresi\'on pasa por $(\overline{X},\overline{Y})$. Luego el \'unico caso posible a partir de los datos es que el intercepto sea cero en todos los casos.

\item Considere el vector
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
 x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
\end{lstlisting}
{\textquestiondown}Cu\'al es el valor que minimiza la suma de las distancias el cuadrado entre estos puntos y el valor mismo?

\textbf{Desarrollo.}
Como se vio en clases el vector pedido es el que sus coordenadas son iguales a la media de los datos que se calcula de la siguiente manera:
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
> mean(x)
[1] 0.573
\end{lstlisting}

\item Considere los siguientes vectores con $x$ como input e $y$ como output
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
 x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
 y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
\end{lstlisting}
{\textquestiondown}Cu\'al es el valor $p$ de test de dos colas para determinar si acaso el $\beta_1$ de la regresi\'on lineal es 0 o no?

\textbf{Desarrollo.}
\begin{lstlisting}[backgroundcolor=\color{Gray!20},frame=none,basicstyle=\ttfamily]
> x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
> y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
> fit <- lm(y ~ x)
> summary(fit)

Call:
lm(formula = y ~ x)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27636 -0.18807  0.01364  0.16595  0.27143 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept)   0.1885     0.2061   0.914    0.391  
x             0.7224     0.3107   2.325    0.053 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.223 on 7 degrees of freedom
Multiple R-squared:  0.4358,	Adjusted R-squared:  0.3552 
F-statistic: 5.408 on 1 and 7 DF,  p-value: 0.05296
\end{lstlisting}
	
\item {\textquestiondown}Cu\'al es la desviaci\'on t\'ipica residual en el problema anterior?

\textbf{Desarrollo.}
Id\'entico al desarrollo anterior.

\end{enumerate}

\end{document}